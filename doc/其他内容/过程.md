## 去年

### 11/13

#### 赛题分析

![image-20241113213606463](过程/image-20241113213606463.png)

【分析】

* 大概率是做A题相关的内容；

【参考文献】

[CSDN-2023数学建模](https://blog.csdn.net/Tech_deer/article/details/134568501)



##### 赛题

问题 1：计数苹果

- [x] 基于提供的收获就绪苹果图像数据集（见附件1），提取图像特征，建立数学模型，计算每张图像中苹果的数量，并绘制附件1中所有苹果分布的直方图。

问题 2：估算苹果的位置

- [ ] 基于提供的收获就绪苹果图像数据集（见附件1），确定每张图像中苹果的位置，以图像的左下角为坐标原点，并绘制附件1中所有苹果几何坐标的二维散点图。

问题 3：估算苹果的成熟状态

- [ ] 基于提供的收获就绪苹果图像数据集（见附件1），建立数学模型，计算每张图像中苹果的成熟度，并绘制附件1中所有苹果成熟度分布的直方图。

问题 4：估算苹果的质量

- [ ] 基于提供的收获就绪苹果图像数据集（见附件1），计算每张图像中苹果的二维面积，以图像的左下角为坐标原点，估算苹果的质量，并绘制附件1中所有苹果质量分布的直方图。

问题 5：苹果的识别

- [ ] 基于提供的收获水果图像数据集（见附件2），提取图像特征，训练一个苹果识别模型，识别附件3中的苹果，并绘制附件3中所有苹果图像ID号的分布直方图。

#### 数据收集

【目的】收集符合题意，且有意义的数据；

#### 数据探索

【时间】11/13

##### 绘图查看数据分布

* 数据分布对模型的影响？

##### 数据集划分

* 划分训练集、测试集和验证集

##### 数据图像质量

* 分辨率高；不同类别之间的颜色区分度高；物体的轮廓清晰；



#### 模型

##### 模型选择 + 模块融合

* 这一部分多看论文
* 多半是选择Visition Transformer的代码

##### 模型比较

* 比较注意力机制和稀疏注意力机制的情况

##### 超参数调整

* 确定好模型之后就是调模型的超参数



#### 代码相关

##### 绘制图像分布的直方图

- [ ] 一个画布绘制一个直方图

``` python
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

def plot_image_histogram(image_path):
    # 加载图像并转换为灰度
    image = Image.open(image_path).convert('L')
    image_np = np.array(image)

    # 计算直方图
    histogram, bin_edges = np.histogram(image_np, bins=256, range=(0, 255))

    # 绘制直方图
    plt.figure()
    plt.title("Grayscale Histogram")
    plt.xlabel("Grayscale Value")
    plt.ylabel("Pixels")
    plt.xlim([0, 255])
    plt.plot(bin_edges[0:-1], histogram)
    plt.show()

# 使用示例
image_path = '../../data/img/desktop.png'  # 替换为你的图像文件路径
plot_image_histogram(image_path)
```



- [ ] 在一个画布上绘制多个

``` python
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

def plot_images_histogram(image_paths, bins=256):
    """
    绘制多张图像的灰度直方图。
    :param image_paths: 包含图像文件路径的列表。
    :param bins: 直方图的柱数。
    """
    # 创建一个画布，根据图像数量动态调整大小
    plt.figure(figsize=(15, 5 * len(image_paths)))

    for i, image_path in enumerate(image_paths, 1):
        # 加载图像并转换为灰度
        image = Image.open(image_path).convert('L')
        image_np = np.array(image)

        # 计算直方图
        histogram, bin_edges = np.histogram(image_np, bins=bins, range=(0, 255))

        # 绘制直方图
        plt.plot(bin_edges[0:-1], histogram, label=f"Image {i}")
    plt.title(f"Grayscale Histogram for Image {i}")
    plt.xlabel("Grayscale Value")
    plt.ylabel("Pixels")
    plt.xlim([0, 255])
    plt.legend()
    plt.tight_layout()
    plt.show()

# 使用示例
image_paths = ['../../data/img/desktop.png', '../../data/img/desktop2.png']  # 替换为你的图像文件路径列表
plot_images_histogram(image_paths)
```

【理解】

* 绘制图像的直方图，也就是绘制图像的像素分布；
  思考：不同宽高的图片不需要考虑将其进行维度变换吗？

【对小白】

* Q1：图像的直方图反应了图像的什么信息？横纵坐标反应了什么？
  A1：图像的直方图反应了图像的像素值信息，横坐标是像素值，范围为（0,255）；纵坐标反应了像素的个数，也就是有多少个像素处于这个范围的值；像素值越大，图越亮，反之越暗；



##### 颜色过滤

【思考】当不同类别的颜色区分度较高时，可以考虑使用颜色阈值对物体进行过滤，然后再计数；

``` python
import cv2
import numpy as np

# 读取图像
image = cv2.imread('../../data/img/apple/apple.png')

# 将图像转换为灰度图
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
cv2.imshow('gray_image', gray_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# 使用阈值分割生成二值化图像
_, binary_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)
cv2.imshow('binary_image', binary_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# 连通区域分析
num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image)

# 统计苹果数量
apple_count = len(stats) - 1  # 减去背景标签

# 输出结果
print(f"苹果数量：{apple_count}")
```

【对小白】

* cv2.connectedComponentsWithStats(binary_image)：对二值化后的图像进行连通性判别；
  判断二值化后的图像是否连续

【优缺点分析】

* 优点：简单方便
* 缺点：不准确，颜色过滤的阈值不够好把控；



#### 模型代码相关

##### 目标检测

【基础认知】

* 目标检测：给一张图片，图片中包含众多的信息，准确求有效的识别出图片里面的信息；
  思考：对于精度而言，模型应该选择Two-Stage类型的模型
* One-stage：只有一个阶段那就是识别，直接预测出图像中可能出现的物体区域；例如：YOLO；
  Two-stage：有两个阶段，分别是建议框提出和建议框内容识别；例如：Faster-RCNN系列；
  总之，不论是One-stage，还是Two-stage；都是针对目标检测模块而言的；

【任务】

* 所以，想要识别出图像里面想要关注的内容，我们需要的就是采用目标检测网络进行的；
  判断是想要精度，还是想要速度，在选择不同的模型；

【之前写过的文章】

内容：用几张LOL图片和在Coco数据集上预训练好Faster-RCNN的网络上进行目标检测网络的微调[1](https://blog.csdn.net/m0_67976097/article/details/142337919?spm=1001.2014.3001.5501)；

Q：怎么完成计数功能；
A：通过额外的条件判断完成即可；

##### 模型评价标准

### 11/14

#### 模型微调

【时间】11/14

* 模型微调，本质上调整的是头部（Head）来适应不同的下游任务；
* Vit本身是一种backbone的思路，所以需要基于vit来做对应的下游任务的组合；
  backbone：作用就是抽取特征；
* 是选择detr，还是vit；
  最后，选择微调detr；

##### 测试detr

【新の技能】

* 上hugging_face下载基于Transformers权重，并应用模型做一些下游任务；

模型权重下载：旧电脑
![image-20241114193441666](过程/image-20241114193439215.png)

【理解】

* 旧电脑的缓存都存在这里；
* 下载的权重文件都在这里

``` python
from transformers import DetrImageProcessor, DetrForObjectDetection
import torch
from PIL import Image
import requests

url = "http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)

# you can specify the revision tag if you don't want the timm dependency
processor = DetrImageProcessor.from_pretrained("../../weight/detr", revision="no_timm")
model = DetrForObjectDetection.from_pretrained("../../weight/detr", revision="no_timm")

inputs = processor(images=image, return_tensors="pt")
outputs = model(**inputs)

# convert outputs (bounding boxes and class logits) to COCO API
# let's only keep detections with score > 0.9
target_sizes = torch.tensor([image.size[::-1]])
results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]

for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
    box = [round(i, 2) for i in box.tolist()]
    print(
            f"Detected {model.config.id2label[label.item()]} with confidence "
            f"{round(score.item(), 3)} at location {box}"
    )
```

****

- [ ] 考虑使用torch.hub加载模型，及其权重

``` python
model = torch.hub.load('facebookresearch/detr:main', 'detr_resnet50', pretrained=True)
```





## Detr_Paper

[reference](https://arxiv.org/pdf/2005.12872)

下面的这些加工的理解，都可以作为其他论文的摘要和相关工作/研究的参考文献；

【本文浓缩】

[1] Detr简化了相关的锚框操作，在目标检测的领域上做到了端到端的理念；

[2] Detr通过二分图匹配去除了锚框操作和极大值抑制操作；

[3] Detr对特定对象进行的损失优化；

#### 11/14

##### task1

- [ ] 弄懂detr，并复现核心代码块

****

【摘要和引言】

- [ ] detr是无监督学习吗？是否需要锚框？

答：不是，也需要对应的数据标注；区别于其他的目标检测网络，模型不需要锚框；

* 锚框：是指对原图像按照一定比例的选取（例如：Faster-RCNN里面的RPN网络）；
  锚框就是对原图像的裁剪等操作
  Q：为什么要设计锚框的思路？
  A：有一定的好处；
* FPN：网络是特征融合网络，也称特征金字塔网络；将不同分辨率的特征进行融合；

- [ ] surrogate regression（替代回归）是什么？

答：目标边界框的预测，本质上就是对框的坐标进行线性回归预测；

传统的网络主要分为任务：①回归框预测；②类别的预测；

- [ ] detr可以抛弃锚框的原因？

答：detr是一种非卷积思路，是一种注意力机制在深度学习的应用；

- [ ] YOLO做到端到端的思路了吗？为什么detr还说自己是端到端的原创？

答：端到端是指，输入直接到输出，而不是将输入进行一步额外的操作后再输出；

- [ ] 论文中的removing duplicate predictions是什么意思？

答：消除对于同一个物体的重复预测；

- [ ] bipartite matching是什么意思？

答：二分图匹配；也就是说一个预测框可以和训练数据中有的框相匹配；
二分图匹配解决了锚框的设计；对于没有的类别设计为没有；

- [ ] detr最多能预测多少个类别？

答：无数个，通过线性层参数预测

- [ ] 如果一个类别在一张图中出现多次，detr怎么输出？

答：detr只是限制了类别数，并没有设计

- [ ] detr到底是固定了输出的类别数？还是固定了每一张图片只能有多少个预测框？

答：类别不是固定的，预测框的数目是固定的。即，每一次最多只能预测出固定大小个数的预测框。一个类别可以识别多个；

优点：每次预测都是最清晰的固定数目个图像；
缺点：对于高分辨率图像的预测，也就是小目标的预测效果不好；

- [ ] detr是不是将每一个对象一一分配？是真实值到预测值，还是真实值到预测值进行对应的，还是两者并行的？

答：将两个集合的元素对应起来

优点：第一次提出无锚框的思路；
缺点：如果预测的数目小于固定值，太多空值，那么计算开销大；如果预测的数据数目大于固定值，那么模型检查不完整；

****

【具体的模型&源码分析】

- [ ] 

****

【损失函数设计】

- [ ] 

![image-20241114213741124](过程/image-20241114213741124.png)

【单词】with respect to 关于

【理解】

* detr的损失是对特定进行的，对特定对象进行的损失优化；
* 将y设为真实物体框的变量；$\hat y$表示这个真实物体特定的集合；

【通俗解释数学】

* arg min：当后面的函数最小值时，参数的分布或值；



## 库的版本

##### 环境配置

* 首先需要创建虚拟环境

``` bash
# 查看已有的虚拟环境
conda env list
# 初始化脚本
conda init
# 创建指定python版本的虚拟环境
conda create -n myenv python=3.8    # myenv为虚拟环境的名字
# 激活虚拟环境
conda activate myenv

### 进一步的其他操作
# 取消激活虚拟环境
conda deactivate myenv
# 删除虚拟环境
conda env remove -n myenv
# 查看虚拟环境下的包
conda/pip list
# 查看虚拟环境相关信息
conda env export -n myenv
```



* 其次，在下载对应的库

``` bash
# 下载transformers
pip install transformers==4.46.2
# 下载torchvision
pip install torchvision==0.16.0+cu118 -f https://download.pytorch.org/whl/cu118/torch_stable.html
# 下载对应的datasets
pip install datasets==3.1.0
# 安装wrapt库
pip install wrapt
```



##### 配置SSH

``` bash
ssh-keygen -t rsa -b 4096 -C "test1113"
```

【理解】

- `ssh-keygen`：这是生成、管理和转换认证密钥的命令行程序。
- `-t rsa`：指定要生成的密钥类型。在这里，`rsa`表示RSA算法，这是一种广泛使用的公钥加密技术。
- `-b 4096`：指定密钥的位数。`4096`表示生成一个4096位的密钥。位数越高，密钥的安全性通常越好，但同时计算量也越大。4096位是一个常用的安全级别，提供了较强的保护。
- `-C "test1113"`：这是一个可选的注释字段，用于给生成的密钥对添加一个标签或注释。这里的`"test1113"`就是你为这个密钥对指定的注释。这个注释可以帮助你识别这个密钥对的用途或与之关联的账户。注释不会影响密钥的生成或使用。

【其他】

* 将SSH的公钥添加到github\gitee\HuggingFace上面，然后克隆代码即可；
  注：huggingface不支持中國的IP

